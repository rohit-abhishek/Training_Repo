{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c5aa8c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get started --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c267b",
   "metadata": {},
   "source": [
    "## First - let's talk about the Chat Completions API\n",
    "\n",
    "1. The simplest way to call an LLM\n",
    "2. It's called Chat Completions because it's saying: \"here is a conversation, please predict what should come next\"\n",
    "3. The Chat Completions API was invented by OpenAI, but it's so popular that everybody uses it!\n",
    "\n",
    "### We will start by calling OpenAI again - but don't worry non-OpenAI people, your time is coming!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a76bfc",
   "metadata": {},
   "source": [
    "# 1. Calling openai using requests package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d22ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key and api_key.startswith(\"sk-proj\"): \n",
    "    pass\n",
    "else: \n",
    "    print(\"OpenAI key not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4d08b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-5-nano',\n",
       " 'messages': [{'role': 'user', 'content': 'Tell me a fun fact'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "headers={\n",
    "    \"Authorization\" : f\"Bearer {api_key}\",\n",
    "    \"Content-Type\" : \"application/json\"\n",
    "}\n",
    "\n",
    "payload={\n",
    "    \"model\": \"gpt-5-nano\",\n",
    "    \"messages\" : [\n",
    "        {\"role\" : \"user\", \"content\": \"Tell me a fun fact\"}\n",
    "    ]\n",
    "}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a3d71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-CUZDfnHNfs2sLha0uvNRtQaAmJfqI',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1761401259,\n",
       " 'model': 'gpt-5-nano-2025-08-07',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Fun fact: Bananas are technically berries, but strawberries aren’t. Botanically, a berry comes from a single flower’s ovary, and bananas fit that definition, while strawberries don’t. Want another fun fact?',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 11,\n",
       "  'completion_tokens': 1013,\n",
       "  'total_tokens': 1024,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 960,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make request to open ai \n",
    "response=requests.post(\n",
    "    \"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2654fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fun fact: Bananas are technically berries, but strawberries aren’t. Botanically, a berry comes from a single flower’s ovary, and bananas fit that definition, while strawberries don’t. Want another fun fact?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the content we are interested in we need to \n",
    "response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160bae4",
   "metadata": {},
   "source": [
    "# Using OpenAI package - To call OpenAI \n",
    "``` \n",
    "Also called Python Client Library. It is just a wrapper around to make call to http endpoint. Helps to work in Pythonic way instead of messy json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f2ccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fun fact: A day on Venus is longer than its year. It takes about 243 Earth days to rotate once, but only about 225 Earth days to orbit the Sun.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "messages=[{\"role\" : \"user\", \"content\": \"Tell me a fun fact\"}]\n",
    "\n",
    "# create openai object - no need to explicitly provide api key. It will by default pick from .env file \n",
    "open_ai=OpenAI()\n",
    "response=open_ai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\", \n",
    "    messages=messages\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d9fd5",
   "metadata": {},
   "source": [
    "# Using OpenAI package - To call Gemini (Google's model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b5bb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one!\\n\\nA group of **owls** is called a **parliament**.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "gemini_base_url=os.getenv(\"GEMINI_BASE_URL\")\n",
    "\n",
    "gemini=OpenAI(base_url=gemini_base_url, api_key=gemini_api_key)\n",
    "response=gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bc34a",
   "metadata": {},
   "source": [
    "# Using OpenAI package - To call Local ollama models like Llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a7a89c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s one:\\n\\n**There is a species of jellyfish that is immortal!**\\n\\nThe Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a type of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal!\\n\\nIsn\\'t that cool?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_api_key=\"ollama\"\n",
    "ollama_base_url=os.getenv(\"OLLAMA_BASE_URL\")\n",
    "\n",
    "ollama=OpenAI(base_url=ollama_base_url, api_key=ollama_api_key)\n",
    "response=ollama.chat.completions.create(model=\"llama3.1\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f66dd",
   "metadata": {},
   "source": [
    "# Day 1 excercise as assignment using ollama models \n",
    "\n",
    "``` \n",
    "Read the content from the website using scraper program provided in headeless manner and ask agent to summarize in most snarky way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8376e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bfeca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e88b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44f3c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import fetch_website_contents\n",
    "\n",
    "# call open ai \n",
    "def summarize(url):\n",
    "    website=fetch_website_contents(url)\n",
    "    ollama=OpenAI(base_url=ollama_base_url, api_key=ollama_api_key)\n",
    "    response=ollama.chat.completions.create(model=\"llama3.1\", messages=messages_for(website))\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68291b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**A website by Edward Donner, because the world wasn't already sufficiently overrun with code and tech startups**\n",
       "\n",
       "This website appears to be a personal blog and portfolio by Edward Donner, who is obsessed with AI and LLMs (Large Language Models). He's a co-founder of Nebula.io, some company that uses AI to help recruiters find talent, and claims it's patented.\n",
       "\n",
       "**Recent Posts:**\n",
       "\n",
       "* He wrote about the awesomeness of something called Agentic AI on AWS (whatever that is)\n",
       "* He wants to connect with you, because who doesn't love a good personal connection\n",
       "* There are some courses and briefings, probably full of buzzwords like \"LLM expert\" and \"leader\"\n",
       "\n",
       "**Outsmart:** An arena where LLMs battle each other in a game of diplomacy and deviousness. Think virtual Robot Wars, but with code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(summarize(\"https://edwarddonner.com\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd19511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
