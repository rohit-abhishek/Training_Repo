{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df668f8",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f03d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "from dotenv import load_dotenv \n",
    "\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI\n",
    "\n",
    "# Lets do little different. Grab ollama models to do this activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b868ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20e717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "ollama_api_key='ollama'\n",
    "llama_model = os.getenv(\"LLAMA3_1_MODEL\")\n",
    "gemma_model = os.getenv(\"GEMMA3_MODEL\")\n",
    "local_base_url=os.getenv(\"OLLAMA_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3723db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama=OpenAI(base_url=local_base_url, api_key=ollama_api_key)\n",
    "gemma=OpenAI(base_url=local_base_url, api_key=ollama_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd20f51",
   "metadata": {},
   "source": [
    "# Scrape the details from Ed Donner's website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed55b393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links=fetch_website_links(url=\"https://edwarddonner.com\")\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06847330",
   "metadata": {},
   "source": [
    "### Step 1 - call Gemma3 model to find which all links are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92015eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df870bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9a8e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the list of links on the website https://edwarddonner.com -\n",
      "Please decide which of these are relevant web links for a brochure about the company, \n",
      "respond with the full https URL in JSON format.\n",
      "Do not include Terms of Service, Privacy, email links.\n",
      "\n",
      "Links (some might be relative links):\n",
      "\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/\n",
      "https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(url=\"https://edwarddonner.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5fa5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url:str, model:OpenAI=gemma, model_name:str=\"gemma3\"):\n",
    "    response=model.chat.completions.create(model=model_name, messages=[\n",
    "        {\"role\" : \"system\", \"content\" : link_system_prompt}, \n",
    "        {\"role\" : \"user\", \"content\" : get_links_user_prompt(url)}], response_format={\"type\" : \"json_object\"\n",
    "    })\n",
    "\n",
    "    result=response.choices[0].message.content\n",
    "    links=json.loads(result)\n",
    "\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "568f6856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page',\n",
       "   'url': 'https://edwarddonner.com/about-me-and-about-nebula/'},\n",
       "  {'type': 'about page', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/posts/'},\n",
       "  {'type': 'careers page', 'url': 'https://www.linkedin.com/in/eddonner/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'},\n",
       "  {'type': 'blog', 'url': 'https://edwarddonner.com/'}]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(url=\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "877eb908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/'},\n",
       "  {'type': 'models', 'url': 'https://huggingface.co/models/'},\n",
       "  {'type': 'datasets', 'url': 'https://huggingface.co/datasets/'},\n",
       "  {'type': 'spaces', 'url': 'https://huggingface.co/spaces/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/'},\n",
       "  {'type': 'documentation',\n",
       "   'url': 'https://huggingface.co/docs/transformers/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/diffusers/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/safetensors/'},\n",
       "  {'type': 'documentation',\n",
       "   'url': 'https://huggingface.co/docs/huggingface_hub/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/tokenizers/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/trl/'},\n",
       "  {'type': 'documentation',\n",
       "   'url': 'https://huggingface.co/docs/transformers.js/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/smolagents/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/peft/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/datasets/'},\n",
       "  {'type': 'documentation',\n",
       "   'url': 'https://huggingface.co/docs/text-generation-inference/'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs/accelerate/'},\n",
       "  {'type': 'enterprise', 'url': 'https://huggingface.co/enterprise/'},\n",
       "  {'type': 'community', 'url': 'https://discuss.huggingface.co'},\n",
       "  {'type': 'status', 'url': 'https://status.huggingface.co/'},\n",
       "  {'type': 'github', 'url': 'https://github.com/huggingface'},\n",
       "  {'type': 'social media', 'url': 'https://twitter.com/huggingface'},\n",
       "  {'type': 'social media',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'}]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call this for hugging face \n",
    "select_relevant_links(url=\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ca199",
   "metadata": {},
   "source": [
    "### Step 2 - Make a brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "044af192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    contents = fetch_website_contents(url)\n",
    "    relevant_links = select_relevant_links(url)\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n### Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link[\"url\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09b86ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## Landing Page:\\n\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\ndeepseek-ai/DeepSeek-OCR\\nUpdated\\nabout 17 hours ago\\n‚Ä¢\\n623k\\n‚Ä¢\\n1.82k\\nPaddlePaddle/PaddleOCR-VL\\nUpdated\\n1 day ago\\n‚Ä¢\\n14.8k\\n‚Ä¢\\n1.07k\\ntencent/HunyuanWorld-Mirror\\nUpdated\\nabout 12 hours ago\\n‚Ä¢\\n5.94k\\n‚Ä¢\\n330\\nkrea/krea-realtime-video\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n179\\nQwen/Qwen3-VL-8B-Instruct\\nUpdated\\n10 days ago\\n‚Ä¢\\n262k\\n‚Ä¢\\n320\\nBrowse 1M+ models\\nSpaces\\nRunning\\n514\\n514\\nveo3.1-fast\\nüê®\\nGenerate videos from text or images\\nRunning\\n15.4k\\n15.4k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nRunning\\non\\nZero\\n225\\n225\\nDeepSeek OCR Demo\\nüÜò\\nAn interactive demo for the DeepSeek-OCR model.\\nRunning\\n2.06k\\n2.06k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\nRunning\\n446\\n446\\nSora 2\\nüìâ\\nGenerate videos from text or images\\nBrowse 400k+ applications\\nDatasets\\nHuggingFaceFW/finewiki\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.66k\\n‚Ä¢\\n105\\nkarpathy/fineweb-edu-100b-shuffle\\nUpdated\\nabout 1 month ago\\n‚Ä¢\\n36k\\n‚Ä¢\\n101\\nnick007x/github-code-2025\\nUpdated\\n10 days ago\\n‚Ä¢\\n9.94k\\n‚Ä¢\\n72\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n36.7k\\n‚Ä¢\\n9.31k\\nHuggingFaceM4/FineVision\\nUpdated\\n4 days ago\\n‚Ä¢\\n229k\\n‚Ä¢\\n402\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at \\n## Relevant Links:\\n\\n\\n### Link: about page\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\ndeepseek-ai/DeepSeek-OCR\\nUpdated\\nabout 17 hours ago\\n‚Ä¢\\n623k\\n‚Ä¢\\n1.82k\\nPaddlePaddle/PaddleOCR-VL\\nUpdated\\n1 day ago\\n‚Ä¢\\n14.8k\\n‚Ä¢\\n1.07k\\ntencent/HunyuanWorld-Mirror\\nUpdated\\nabout 12 hours ago\\n‚Ä¢\\n5.94k\\n‚Ä¢\\n330\\nkrea/krea-realtime-video\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n179\\nQwen/Qwen3-VL-8B-Instruct\\nUpdated\\n10 days ago\\n‚Ä¢\\n262k\\n‚Ä¢\\n320\\nBrowse 1M+ models\\nSpaces\\nRunning\\n514\\n514\\nveo3.1-fast\\nüê®\\nGenerate videos from text or images\\nRunning\\n15.4k\\n15.4k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nRunning\\non\\nZero\\n225\\n225\\nDeepSeek OCR Demo\\nüÜò\\nAn interactive demo for the DeepSeek-OCR model.\\nRunning\\n2.06k\\n2.06k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\nRunning\\n446\\n446\\nSora 2\\nüìâ\\nGenerate videos from text or images\\nBrowse 400k+ applications\\nDatasets\\nHuggingFaceFW/finewiki\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.66k\\n‚Ä¢\\n105\\nkarpathy/fineweb-edu-100b-shuffle\\nUpdated\\nabout 1 month ago\\n‚Ä¢\\n36k\\n‚Ä¢\\n101\\nnick007x/github-code-2025\\nUpdated\\n10 days ago\\n‚Ä¢\\n9.94k\\n‚Ä¢\\n72\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n36.7k\\n‚Ä¢\\n9.31k\\nHuggingFaceM4/FineVision\\nUpdated\\n4 days ago\\n‚Ä¢\\n229k\\n‚Ä¢\\n402\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at \\n\\n### Link: models\\nModels ‚Äì Hugging Face\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEdit Models filters\\nMain\\nTasks\\nLibraries\\nLanguages\\nLicenses\\nOther\\nTasks\\nText Generation\\nAny-to-Any\\nImage-Text-to-Text\\nImage-to-Text\\nImage-to-Image\\nText-to-Image\\nText-to-Video\\nText-to-Speech\\n+ 42\\nParameters\\nReset Parameters\\n< 1B\\n6B\\n12B\\n32B\\n128B\\n> 500B\\n< 1B\\n> 500B\\nLibraries\\nPyTorch\\ngoogle-tensorflow\\nTensorFlow\\nJAX\\nTransformers\\nDiffusers\\nSafetensors\\nONNX\\nGGUF\\nTransformers.js\\nMLX\\nKeras\\n+ 41\\nApps\\nvLLM\\nTGI\\nllama.cpp\\nMLX LM\\nLM Studio\\nOllama\\nJan\\n+ 13\\nInference Providers\\nGroq\\nNovita\\nNebius AI\\nCerebras\\nSambaNova\\nNscale\\nfal\\nHyperbolic\\n+ 9\\nApply filters\\nModels\\nFull-text search\\nInference Available\\nAdd filters\\nSort:\\xa0\\n\\t\\tTrending\\ndeepseek-ai/DeepSeek-OCR\\nImage-Text-to-Text\\n‚Ä¢\\n3B\\n‚Ä¢\\nUpdated\\nabout 17 hours ago\\n‚Ä¢\\n623k\\n‚Ä¢\\n1.82k\\nPaddlePaddle/PaddleOCR-VL\\nImage-Text-to-Text\\n‚Ä¢\\n1.0B\\n‚Ä¢\\nUpdated\\n1 day ago\\n‚Ä¢\\n14.8k\\n‚Ä¢\\n1.07k\\ntencent/HunyuanWorld-Mirror\\nImage-to-3D\\n‚Ä¢\\nUpdated\\nabout 12 hours ago\\n‚Ä¢\\n5.94k\\n‚Ä¢\\n330\\nkrea/krea-realtime-video\\nText-to-Video\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n179\\nQwen/Qwen3-VL-8B-Instruct\\nImage-Text-to-Text\\n‚Ä¢\\n9B\\n‚Ä¢\\nUpdated\\n10 days ago\\n‚Ä¢\\n262k\\n‚Ä¢\\n‚Ä¢\\n320\\nnanonets/Nanonets-OCR2-3B\\nImage-Text-to-Text\\n‚Ä¢\\n4B\\n‚Ä¢\\nUpdated\\n9 days ago\\n‚Ä¢\\n24.5k\\n‚Ä¢\\n407\\nPhr00t/Qwen-Image-Edit-Rapid-AIO\\nText-to-Image\\n‚Ä¢\\nUpdated\\nabout 19 hours ago\\n‚Ä¢\\n429\\nlovis93/next-scene-qwen-image-lora-2509\\nImage-to-Image\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n26.7k\\n‚Ä¢\\n387\\nQwen/Qwen3-VL-32B-Instruct\\nImage-Text-to-Text\\n‚Ä¢\\n33B\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n16.6k\\n‚Ä¢\\n87\\nnvidia/omnivinci\\nFeature Extraction\\n‚Ä¢\\nUpdated\\n2 days ago\\n‚Ä¢\\n484\\n‚Ä¢\\n84\\nQwen/Qwen3-VL-2B-Instruct\\nImage-Text-to-Text\\n‚Ä¢\\n2B\\n‚Ä¢\\nUpdated\\n2 days ago\\n‚Ä¢\\n23.8k\\n‚Ä¢\\n83\\nallenai/olmOCR-2-7B-1025-FP8\\nImage-to-Text\\n‚Ä¢\\n8B\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n3.44k\\n‚Ä¢\\n75\\nzai-org/GLM-4.6\\nText Generation\\n‚Ä¢\\n357B\\n‚Ä¢\\nUpdated\\n25 days ago\\n‚Ä¢\\n59.5k\\n‚Ä¢\\n‚Ä¢\\n878\\nJunhaoZhuang/FlashVSR\\nVideo-to-Video\\n‚Ä¢\\nUpdated\\n7 days ago\\n‚Ä¢\\n105\\nPokeeAI/pokee_research_7b\\nText Generation\\n‚Ä¢\\n8B\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n3.21k\\n‚Ä¢\\n69\\nPhr00t/WAN2.2-14B-Rapid-AllInOne\\nImage-to-Vide\\n\\n### Link: datasets\\nDatasets ‚Äì Hugging Face\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEdit Datasets filters\\nMain\\nTasks\\nLibraries\\nLanguages\\nLicenses\\nOther\\nModalities\\n3D\\nAudio\\nDocument\\nGeospatial\\nImage\\nTabular\\nText\\nTime-series\\nVideo\\nSize\\n\\t\\t\\t(rows)\\nReset Size\\n< 1K\\n> 1T\\nFormat\\njson\\ncsv\\nparquet\\nimagefolder\\nsoundfolder\\nwebdataset\\ntext\\narrow\\nApply filters\\nDatasets\\n532,035\\nFull-text search\\nAdd filters\\nSort:\\xa0\\n\\t\\tTrending\\nHuggingFaceFW/finewiki\\nViewer\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n61.6M\\n‚Ä¢\\n2.66k\\n‚Ä¢\\n105\\nkarpathy/fineweb-edu-100b-shuffle\\nViewer\\n‚Ä¢\\nUpdated\\nabout 1 month ago\\n‚Ä¢\\n97.2M\\n‚Ä¢\\n36k\\n‚Ä¢\\n101\\nnick007x/github-code-2025\\nViewer\\n‚Ä¢\\nUpdated\\n10 days ago\\n‚Ä¢\\n147M\\n‚Ä¢\\n9.94k\\n‚Ä¢\\n72\\nfka/awesome-chatgpt-prompts\\nViewer\\n‚Ä¢\\nUpdated\\nJan 6\\n‚Ä¢\\n203\\n‚Ä¢\\n36.7k\\n‚Ä¢\\n9.31k\\nHuggingFaceM4/FineVision\\nViewer\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n24.2M\\n‚Ä¢\\n229k\\n‚Ä¢\\n402\\nOpen-Bee/Honey-Data-15M\\nUpdated\\n10 days ago\\n‚Ä¢\\n85\\n‚Ä¢\\n37\\nQingyanBai/Ditto-1M\\nUpdated\\n4 days ago\\n‚Ä¢\\n11.2k\\n‚Ä¢\\n25\\nAgent-Ark/Toucan-1.5M\\nViewer\\n‚Ä¢\\nUpdated\\n22 days ago\\n‚Ä¢\\n1.65M\\n‚Ä¢\\n13.5k\\n‚Ä¢\\n153\\njbarrow/CommonForms\\nViewer\\n‚Ä¢\\nUpdated\\n8 days ago\\n‚Ä¢\\n487k\\n‚Ä¢\\n1.13k\\n‚Ä¢\\n35\\nnick007x/arxiv-papers\\nViewer\\n‚Ä¢\\nUpdated\\n11 days ago\\n‚Ä¢\\n2.55M\\n‚Ä¢\\n7.01k\\n‚Ä¢\\n41\\nraidium/CuriaBench\\nViewer\\n‚Ä¢\\nUpdated\\n2 days ago\\n‚Ä¢\\n101k\\n‚Ä¢\\n281\\n‚Ä¢\\n17\\nethanolivertroy/nist-cybersecurity-training\\nViewer\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n531k\\n‚Ä¢\\n928\\n‚Ä¢\\n32\\nRUC-DataLab/DataScience-Instruct-500K\\nViewer\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n26.2k\\n‚Ä¢\\n2.92k\\n‚Ä¢\\n17\\nopenai/gdpval\\nViewer\\n‚Ä¢\\nUpdated\\nabout 1 month ago\\n‚Ä¢\\n220\\n‚Ä¢\\n43k\\n‚Ä¢\\n245\\nHuggingFaceFW/finepdfs\\nViewer\\n‚Ä¢\\nUpdated\\nSep 8\\n‚Ä¢\\n475M\\n‚Ä¢\\n47.6k\\n‚Ä¢\\n624\\nash56/ShiftySpeech\\nViewer\\n‚Ä¢\\nUpdated\\n1 day ago\\n‚Ä¢\\n3M\\n‚Ä¢\\n362\\n‚Ä¢\\n15\\nuv-scripts/ocr\\nUpdated\\n1 day ago\\n‚Ä¢\\n191\\n‚Ä¢\\n33\\nFBK-MT/MCIF\\nViewer\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n3.84k\\n‚Ä¢\\n2.7k\\n‚Ä¢\\n13\\nopenai/gsm8k\\nViewer\\n‚Ä¢\\nUpdated\\nJan 4, 2024\\n‚Ä¢\\n17.6k\\n‚Ä¢\\n380k\\n‚Ä¢\\n912\\nSalesforce/Webscale-RL\\nViewer\\n‚Ä¢\\nUpdated\\n12 days ago\\n‚Ä¢\\n1.11M\\n‚Ä¢\\n9.26k\\n‚Ä¢\\n77\\nHuggingFaceFW/fineweb\\nViewer\\n‚Ä¢\\nUpdated\\nJul 11\\n‚Ä¢\\n52.5B\\n‚Ä¢\\n276k\\n‚Ä¢\\n2.4k\\nBSC-LT/multi_lmentry\\nViewer\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n938k\\n‚Ä¢\\n142\\n‚Ä¢\\n9\\nHuggingFaceM4/FineVisionMax\\nViewer\\n‚Ä¢\\nUpdated\\n4\\n\\n### Link: spaces\\nSpaces - Hugging Face\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nSpaces\\n¬∑\\nThe AI App Directory\\nNew Space\\nGet PRO\\nLearn more\\nImage Generation\\nVideo Generation\\nText Generation\\nLanguage Translation\\nSpeech Synthesis\\n3D Modeling\\nObject Detection\\nText Analysis\\nImage Editing\\nCode Generation\\nQuestion Answering\\nData Visualization\\nVoice Cloning\\nBackground Removal\\nImage Upscaling\\nOCR\\nDocument Analysis\\nVisual QA\\nImage Captioning\\nChatbots\\nSentiment Analysis\\nText Summarization\\nMusic Generation\\nMedical Imaging\\nFinancial Analysis\\nGame AI\\nModel Benchmarking\\nFine Tuning Tools\\nDataset Creation\\nPose Estimation\\nFace Recognition\\nAnomaly Detection\\nRecommendation Systems\\nCharacter Animation\\nStyle Transfer\\nImage\\nSpaces of the week\\n20 Oct 2025\\nFilters\\n(0)\\nSort:\\xa0\\n\\t\\tRelevance\\nRunning\\non\\nCPU Upgrade\\n56\\nKrea Realtime Video\\nüëÅ\\nGenerate videos from webcam, uploaded video, or text prompts\\nmultimodalart\\n4 days ago\\nRunning\\non\\nZero\\n225\\nDeepSeek OCR Demo\\nüÜò\\nAn interactive demo for the DeepSeek-OCR model.\\nkhang119966\\n5 days ago\\nRunning\\n128\\nPaddleOCR-VL Online Demo\\nüìà\\nRecognize text and elements in images\\nPaddlePaddle\\n2 days ago\\nRunning\\non\\nZero\\n33\\nWithAnyone Demo\\nüèÉ\\nWithAnyone is capable of generating high-quality, controllab\\nWithAnyone\\n9 days ago\\nRunning\\n28\\nGradio Hackathon Registration Winter 25\\nüìù\\nGradio Agents & MCP Hackathon Winter 2025 Registration Page\\nysharma\\n11 days ago\\nRunning\\non\\nZero\\n29\\nMobileLLM-Pro\\nüëÅ\\nChat with MobileLLM-Pro to get responses\\nakhaliq\\n3 days ago\\nRunning\\non\\nZero\\nMCP\\n17\\nQwen3 VL HF Demo\\nüèâ\\nChat using Qwen3-VL for Image, Video, PDF, and GIF\\nprithivMLmods\\n9 days ago\\nRunning\\non\\nZero\\n18\\nDiffusion GPT\\nüñä\\nGenerate Shakespearean text using a diffusion model\\nmultimodalart\\n12 days ago\\nAll running apps, trending first\\nRunning\\n514\\nveo3.1-fast\\nüê®\\nGenerate videos from text or images\\nakhaliq\\n1 day ago\\nRunning\\n15.4k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nenzostvs\\n1 day ago\\nRunning\\non\\nZero\\n225\\nDeepSeek OCR Demo\\nüÜò\\nAn interactive demo for the DeepS\\n\\n### Link: documentation\\nHugging Face - Documentation\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nDocumentation\\nHub & Client Libraries\\nHub\\nHost Git-based models, datasets, and Spaces on the HF Hub\\nHub Python Library\\nPython client to interact with the Hugging Face Hub\\nHuggingface.js\\nJavaScript libraries for Hugging Face with built-in TS types\\nTasks\\nExplore demos, models, and datasets for any ML tasks\\nDataset viewer\\nAPI for metadata, stats, and content of HF Hub datasets\\nDeployment & Inference\\nInference Providers\\nCall 200k+ models hosted by our 10+ Inference partners\\nInference Endpoints (dedicated)\\nDeploy models on dedicated & fully managed infrastructure on HF\\nDeploying on AWS\\nTrain/deploy models from Hugging Face to AWS with DLCs\\nText Generation Inference\\nServe language models with TGI optimized toolkit\\nText Embeddings Inference\\nServe embeddings models with TEI optimized toolkit\\nMicrosoft Azure\\nDeploy Hugging Face models on Microsoft Azure\\nCore ML Libraries\\nTransformers\\nState-of-the-art AI models for PyTorch\\nDiffusers\\nState-of-the-art Diffusion models in PyTorch\\nDatasets\\nAccess & share datasets for any ML tasks\\nTransformers.js\\nState-of-the-art ML running directly in your browser\\nTokenizers\\nFast tokenizers optimized for research & production\\nEvaluate\\nEvaluate and compare models performance\\ntimm\\nState-of-the-art vision models: layers, optimizers, and utilities\\nSentence Transformers\\nEmbeddings, Retrieval, and Reranking\\nKernels\\nLoad and run compute kernels from the Hugging Face Hub\\nTraining & Optimization\\nPEFT\\nParameter-efficient finetuning for large language models\\nAccelerate\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nOptimum\\nOptimize HF Transformers for faster training/inference\\nAWS Trainium & Inferentia\\nTrain/deploy Transformers/Diffusers on AWS\\nTRL\\nTrain transformers LMs with reinforcement learning\\nSafetensors\\nSafe way to store/distribute neural network weights\\nBitsandbytes\\nOptimize and quantize models with bitsandbytes\\nLighteval\\nAll-\\n\\n### Link: documentation\\nTransformers\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTransformers documentation\\nTransformers\\nTransformers\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv4.57.1\\nv4.56.2\\nv4.55.4\\nv4.53.3\\nv4.52.3\\nv4.51.3\\nv4.50.0\\nv4.49.0\\nv4.48.2\\nv4.47.1\\nv4.46.3\\nv4.45.2\\nv4.44.2\\nv4.43.4\\nv4.42.4\\nv4.41.2\\nv4.40.2\\nv4.39.3\\nv4.38.2\\nv4.37.2\\nv4.36.1\\nv4.35.2\\nv4.34.1\\nv4.33.3\\nv4.32.1\\nv4.31.0\\nv4.30.0\\nv4.29.1\\nv4.28.1\\nv4.27.2\\nv4.26.1\\nv4.25.1\\nv4.24.0\\nv4.23.1\\nv4.22.2\\nv4.21.3\\nv4.20.1\\nv4.19.4\\nv4.18.0\\nv4.17.0\\nv4.16.2\\nv4.15.0\\nv4.14.1\\nv4.13.0\\nv4.12.5\\nv4.11.3\\nv4.10.1\\nv4.9.2\\nv4.8.2\\nv4.7.0\\nv4.6.0\\nv4.5.1\\nv4.4.2\\nv4.3.3\\nv4.2.2\\nv4.1.1\\nv4.0.1\\nv3.5.1\\nv3.4.0\\nv3.3.1\\nv3.2.0\\nv3.1.0\\nv3.0.2\\nv2.11.0\\nv2.10.0\\nv2.9.1\\nv2.8.0\\nv2.7.0\\nv2.6.0\\nv2.5.1\\nv2.4.1\\nv2.3.0\\nv2.2.2\\nv2.1.1\\nv2.0.0\\nv1.2.0\\nv1.1.0\\nv1.0.0\\ndoc-builder-html\\nAR\\nDE\\nEN\\nES\\nFR\\nHI\\nIT\\nJA\\nKO\\nPT\\nZH\\nGet started\\nTransformers\\nInstallation\\nQuickstart\\nBase classes\\nInference\\nTraining\\nQuantization\\nExport to production\\nResources\\nContribute\\nAPI\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nCopy page\\nTransformers\\nTransformers acts as the model-definition framework for state-of-the-art machine learning models in text, computer\\nvision, audio, video, and multimodal model, for both inference and training.\\nIt centralizes the model definition so that this definition is agreed upon across the ecosystem.\\ntra\\n\\n### Link: documentation\\nDiffusers\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nDiffusers documentation\\nDiffusers\\nDiffusers\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv0.35.1\\nv0.34.0\\nv0.33.1\\nv0.32.2\\nv0.31.0\\nv0.30.3\\nv0.29.2\\nv0.28.2\\nv0.27.2\\nv0.26.3\\nv0.25.1\\nv0.24.0\\nv0.23.1\\nv0.22.3\\nv0.21.0\\nv0.20.0\\nv0.19.3\\nv0.18.2\\nv0.17.1\\nv0.16.0\\nv0.15.0\\nv0.14.0\\nv0.13.0\\nv0.12.0\\nv0.11.0\\nv0.10.2\\nv0.9.0\\nv0.8.0\\nv0.7.0\\nv0.6.0\\nv0.5.1\\nv0.4.1\\nv0.3.0\\nv0.2.4\\nEN\\nJA\\nKO\\nPT\\nZH\\nGet started\\nDiffusers\\nInstallation\\nQuickstart\\nBasic performance\\nDiffusionPipeline\\nAdapters\\nInference\\nInference optimization\\nHybrid Inference\\nModular Diffusers\\nTraining\\nQuantization\\nModel accelerators and hardware\\nSpecific pipeline examples\\nResources\\nAPI\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nDiffusers\\nDiffusers is a library of state-of-the-art pretrained diffusion models for generating videos, images, and audio.\\nThe library revolves around the\\nDiffusionPipeline\\n, an API designed for:\\neasy inference with only a few lines of code\\nflexibility to mix-and-match pipeline components (models, schedulers)\\nloading and using adapters like LoRA\\nDiffusers also comes with optimizations - such as offloading and quantization - to ensure even the largest models are accessible on memory-constrained devices. If memory is not an issue, Diffusers supports torch.compile to boost in\\n\\n### Link: documentation\\nSafetensors\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nSafetensors documentation\\nSafetensors\\nSafetensors\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv0.5.0-rc.0\\nv0.3.2\\nv0.2.9\\nEN\\nGetting started\\nü§ó Safetensors\\nSpeed Comparison\\nTensor Sharing in Pytorch\\nMetadata Parsing\\nConvert weights to safetensors\\nAPI\\nTorch API\\nTensorflow API\\nPaddlePaddle API\\nFlax API\\nNumpy API\\nYou are viewing\\nmain\\nversion, which requires\\ninstallation from source\\n. If you\\'d like\\n\\t\\t\\tregular pip install, checkout the latest stable version (\\nv0.5.0-rc.0\\n).\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nSafetensors\\nSafetensors is a new simple format for storing tensors safely (as opposed to pickle) and that is still fast (zero-copy). Safetensors is really\\nfast üöÄ\\n.\\nInstallation\\nwith pip:\\nCopied\\npip\\ninstall\\nsafetensors\\nwith conda:\\nCopied\\nconda\\ninstall\\n-c huggingface safetensors\\nUsage\\nLoad tensors\\nCopied\\nfrom\\nsafetensors\\nimport\\nsafe_open\\n\\ntensors = {}\\nwith\\nsafe_open(\\n\"model.safetensors\"\\n, framework=\\n\"pt\"\\n, device=\\n0\\n)\\nas\\nf:\\nfor\\nk\\nin\\nf.keys():\\n        tensors[k] = f.get_tensor(k)\\nLoading only part of the tensors (interesting when running on multiple GPU)\\nCopied\\nfrom\\nsafetensors\\nimport\\nsafe_open\\n\\ntensors = {}\\nwith\\nsafe_open(\\n\"model.safetensors\"\\n, framework=\\n\"pt\"\\n, device=\\n0\\n)\\nas\\nf:\\n    tensor_slice = f.get_slice(\\n\"embeddi\\n\\n### Link: documentation\\nü§ó Hub client library\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nHub Python Library documentation\\nü§ó Hub client library\\nHub Python Library\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv1.0.0.rc7\\nv0.36.0\\nv0.35.3\\nv0.34.6\\nv0.33.5\\nv0.32.6\\nv0.31.4\\nv0.30.2\\nv0.29.3\\nv0.28.1\\nv0.27.1\\nv0.26.5\\nv0.25.2\\nv0.24.7\\nv0.23.5\\nv0.22.2\\nv0.21.4\\nv0.20.3\\nv0.19.3\\nv0.18.0.rc0\\nv0.17.3\\nv0.16.3\\nv0.15.1\\nv0.14.1\\nv0.13.4\\nv0.12.1\\nv0.11.0\\nv0.10.1\\nv0.9.1\\nv0.8.1\\nv0.7.0.rc0\\nv0.6.0.rc0\\nv0.5.1\\nCN\\nDE\\nEN\\nFR\\nHI\\nKO\\nTM\\nGet started\\nHome\\nQuickstart\\nInstallation\\nHow-to guides\\nOverview\\nDownload files\\nUpload files\\nUse the CLI\\nHfFileSystem\\nRepository\\nSearch\\nInference\\nInference Endpoints\\nJobs\\nCommunity Tab\\nCollections\\nCache\\nModel Cards\\nManage your Space\\nIntegrate a library\\nWebhooks\\nConceptual guides\\nGit vs HTTP paradigm\\nMigrating to huggingface_hub v1.0\\nReference\\nOverview\\nAuthentication\\nEnvironment variables\\nHugging Face Hub API\\nCLI\\nDownloading files\\nMixins & serialization methods\\nInference Types\\nInference Client\\nInference Endpoints\\nMCP Client\\nHfFileSystem\\nUtilities\\nDiscussions and Pull Requests\\nCache-system reference\\nRepo Cards and Repo Card Data\\nSpace runtime\\nCollections\\nTensorBoard logger\\nWebhooks server\\nSerialization\\nStrict dataclasses\\nOAuth\\nJobs\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nCopy page\\nü§ó Hub client library\\nThe\\nhug\\n\\n### Link: documentation\\nTokenizers\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTokenizers documentation\\nTokenizers\\nTokenizers\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv0.20.3\\nv0.13.4.rc2\\nv0.10.0\\nv0.9.4\\nEN\\nGetting started\\nü§ó Tokenizers\\nQuicktour\\nInstallation\\nThe tokenization pipeline\\nComponents\\nTraining from memory\\nAPI\\nInput Sequences\\nEncode Inputs\\nTokenizer\\nEncoding\\nAdded Tokens\\nModels\\nNormalizers\\nPre-tokenizers\\nPost-processors\\nTrainers\\nDecoders\\nVisualizer\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nTokenizers\\nFast State-of-the-art tokenizers, optimized for both research and\\nproduction\\nü§ó Tokenizers\\nprovides an\\nimplementation of today‚Äôs most used tokenizers, with a focus on\\nperformance and versatility. These tokenizers are also used in\\nü§ó Transformers\\n.\\nMain features:\\nTrain new vocabularies and tokenize, using today‚Äôs most used tokenizers.\\nExtremely fast (both training and tokenization), thanks to the Rust implementation. Takes less than 20 seconds to tokenize a GB of text on a server‚Äôs CPU.\\nEasy to use, but also extremely versatile.\\nDesigned for both research and production.\\nFull alignment tracking. Even with destructive normalization, it‚Äôs always possible to get the part of the original sentence that corresponds to any token.\\nDoes all the pre-processing: Truncation, Padding, add the special tokens y\\n\\n### Link: documentation\\nTRL - Transformer Reinforcement Learning\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTRL documentation\\nTRL - Transformer Reinforcement Learning\\nTRL\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv0.24.0\\nv0.23.1\\nv0.22.2\\nv0.21.0\\nv0.20.0\\nv0.19.1\\nv0.18.1\\nv0.17.0\\nv0.16.1\\nv0.15.2\\nv0.14.0\\nv0.13.0\\nv0.12.2\\nv0.11.4\\nv0.10.1\\nv0.9.6\\nv0.8.6\\nv0.7.11\\nv0.6.0\\nv0.5.0\\nv0.4.7\\nv0.3.1\\nv0.2.1\\nv0.1.1\\nEN\\nGetting started\\nTRL\\nInstallation\\nQuickstart\\nConceptual Guides\\nDataset Formats\\nPaper Index\\nExperimental\\nHow-to guides\\nCommand Line Interface (CLI)\\nTraining using Jobs\\nCustomizing the Training\\nReducing Memory Usage\\nSpeeding Up Training\\nDistributing Training\\nUsing Trained Models\\nIntegrations\\nDeepSpeed\\nKernels Hub\\nLiger Kernel\\nPEFT\\nTrackio\\nUnsloth\\nvLLM\\nExamples\\nExample Overview\\nCommunity Tutorials\\nLoRA Without Regret\\nSentiment Tuning\\nMulti Adapter RLHF\\nAPI\\nTrainers\\nBCO\\nCPO\\nDPO\\nOnline DPO\\nGKD\\nGRPO\\nKTO\\nNash-MD\\nORPO\\nPPO\\nPRM\\nReward\\nRLOO\\nSFT\\nXPO\\nModel Classes\\nModel Utilities\\nBest of N Sampling\\nJudges\\nCallbacks\\nData Utilities\\nReward Functions\\nScript Utilities\\nOthers\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nCopy page\\nTRL - Transformer Reinforcement Learning\\nTRL is a full stack library where we provide a set of tools to train transformer language models with methods like Supervised Fine-Tuning (SFT), Group Relative\\n\\n### Link: documentation\\nTransformers.js\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTransformers.js documentation\\nTransformers.js\\nTransformers.js\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv3.0.0\\nv2.17.2\\nEN\\nü§ó Transformers.js\\nGet started\\nInstallation\\nThe pipeline API\\nCustom usage\\nTutorials\\nBuilding a Vanilla JS Application\\nBuilding a React Application\\nBuilding a Next.js Application\\nBuilding a Browser Extension\\nBuilding an Electron Application\\nServer-side Inference in Node.js\\nDeveloper Guides\\nRunning models on WebGPU\\nUsing quantized models (dtypes)\\nAccessing Private/Gated Models\\nServer-side Audio Processing\\nAPI Reference\\nIndex\\nPipelines\\nModels\\nTokenizers\\nProcessors\\nConfigs\\nEnvironment variables\\nBackends\\nGeneration\\nUtilities\\nYou are viewing\\nmain\\nversion, which requires\\ninstallation from source\\n. If you\\'d like\\n\\t\\t\\tregular npm install, checkout the latest stable version (\\nv3.0.0\\n).\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nCopy page\\nTransformers.js\\nState-of-the-art Machine Learning for the Web\\nRun ü§ó Transformers directly in your browser, with no need for a server!\\nTransformers.js is designed to be functionally equivalent to Hugging Face‚Äôs\\ntransformers\\npython library, meaning you can run the same pretrained models using a very similar API. These models support common tasks in different modalities, such as\\n\\n### Link: documentation\\nsmolagents\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nsmolagents documentation\\nsmolagents\\nsmolagents\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv1.22.0\\nv1.21.2\\nv1.20.0\\nv1.19.0\\nv1.18.0\\nv1.17.0\\nv1.16.1\\nv1.15.0\\nv1.14.0\\nv1.13.0\\nv1.12.0\\nv1.11.0\\nv1.10.0\\nv1.9.2\\nv1.8.1\\nv1.7.0\\nv1.6.0\\nv1.5.1\\nv1.4.1\\nv1.3.0\\nv1.2.2\\nv1.1.0\\nv0.1.3\\nEN\\nHI\\nKO\\nZH\\nGet started\\nIntroduction\\nInstallation options\\nGuided tour\\nTutorials\\n‚ú® Building good agents\\nüìä Inspect your agent runs using telemetry\\nüõ†Ô∏è Tools - in-depth guide\\nüõ°Ô∏è Secure code execution\\nüìö Manage your agent\\'s memory\\nConceptual guides\\nü§ñ What are agents?\\nü§î How do Multi-step agents work?\\nExamples\\nSelf-correcting Text-to-SQL\\nMaster your knowledge base with agentic RAG\\nOrchestrate a multi-agent system\\nBuild a web browser agent using vision models\\nUsing different models\\nHuman-in-the-Loop: Customize agent plan interactively\\nAsync Applications with Agents\\nReference\\nAgent-related objects\\nModel-related objects\\nTools\\nTool-related objects\\nBuilt-in Tools\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nCopy page\\nsmolagents\\nWhat is smolagents?\\nsmolagents\\nis an open-source Python library designed to make it extremely easy to build and run agents using just a few lines of code.\\nKey features of\\nsmolagents\\ninclude:\\n‚ú®\\nSimplicity\\n: The logic for agents fits in ~thousand lines of \\n\\n### Link: documentation\\nPEFT\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nPEFT documentation\\nPEFT\\nPEFT\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv0.17.0\\nv0.16.0\\nv0.15.0\\nv0.14.0\\nv0.13.0\\nv0.12.0\\nv0.11.0\\nv0.10.0\\nv0.9.0\\nv0.8.2\\nv0.7.1\\nv0.6.2\\nEN\\nGet started\\nü§ó PEFT\\nQuicktour\\nInstallation\\nTutorial\\nConfigurations and models\\nIntegrations\\nPEFT method guides\\nPrompt-based methods\\nLoRA methods\\nIA3\\nDeveloper guides\\nModel merging\\nQuantization\\nLoRA\\nCustom models\\nAdapter injection\\nMixed adapter types\\ntorch.compile\\nContribute to PEFT\\nTroubleshooting\\nPEFT checkpoint format\\nü§ó Accelerate integrations\\nDeepSpeed\\nFully Sharded Data Parallel\\nConceptual guides\\nAdapters\\nSoft prompts\\nIA3\\nOFT/BOFT\\nAPI reference\\nMain classes\\nAutoPeftModel\\nPEFT model\\nPEFT types\\nConfiguration\\nTuner\\nAdapters\\nAdaLoRA\\nIA3\\nLlama-Adapter\\nLoHa\\nLoKr\\nLoRA\\nX-LoRA\\nLyCORIS\\nMultitask Prompt Tuning\\nOFT\\nBOFT\\nPolytropon\\nP-tuning\\nPrefix tuning\\nPrompt tuning\\nLayernorm tuning\\nVeRA\\nFourierFT\\nVB-LoRA\\nHRA\\nCPT\\nBone\\nTrainable Tokens\\nRandLora\\nSHiRA\\nC3A\\nMiSS\\nUtilities\\nModel merge\\nHelpers\\nHotswapping adapters\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nPEFT\\nü§ó PEFT (Parameter-Efficient Fine-Tuning) is a library for efficiently adapting large pretrained models to various downstream applications without fine-tuning all of a model‚Äôs parameters because it is prohibitively costly.\\n\\n### Link: documentation\\nDatasets\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nDatasets documentation\\nDatasets\\nDatasets\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv4.3.0\\nv4.2.0\\nv4.1.1\\nv4.0.0\\nv3.6.0\\nv3.5.1\\nv3.4.1\\nv3.3.2\\nv3.2.0\\nv3.1.0\\nv3.0.2\\nv2.21.0\\nv2.20.0\\nv2.19.0\\nv2.18.0\\nv2.17.1\\nv2.16.1\\nv2.15.0\\nv2.14.7\\nv2.13.2\\nv2.12.0\\nv2.11.0\\nv2.10.0\\nv2.9.0\\nv2.8.0\\nv2.7.1\\nv2.6.2\\nv2.5.2\\nv2.4.0\\nv2.3.2\\nv2.2.1\\nv2.1.0\\nv2.0.0\\nv1.18.3\\nv1.17.0\\nv1.16.1\\nv1.15.1\\nv1.14.0\\nv1.13.3\\nv1.12.1\\nv1.11.0\\nv1.10.2\\nv1.9.0\\nv1.8.0\\nv1.7.0\\nv1.6.2\\nv1.5.0\\nv1.4.1\\nv1.3.0\\nv1.2.1\\nv1.1.3\\nv1.0.2\\nv0.4.0\\nv0.3.0\\nEN\\nGet started\\nü§ó Datasets\\nQuickstart\\nInstallation\\nTutorials\\nOverview\\nLoad a dataset from the Hub\\nKnow your dataset\\nPreprocess\\nCreate a dataset\\nShare a dataset to the Hub\\nHow-to guides\\nOverview\\nGeneral usage\\nLoad\\nProcess\\nStream\\nUse with PyTorch\\nUse with TensorFlow\\nUse with NumPy\\nUse with JAX\\nUse with Pandas\\nUse with Polars\\nUse with PyArrow\\nUse with Spark\\nCache management\\nCloud storage\\nSearch index\\nCLI\\nTroubleshooting\\nAudio\\nLoad audio data\\nProcess audio data\\nCreate an audio dataset\\nVision\\nLoad image data\\nProcess image data\\nCreate an image dataset\\nDepth estimation\\nImage classification\\nSemantic segmentation\\nObject detection\\nLoad video data\\nCreate a video dataset\\nLoad document data\\nCreate a document dataset\\nText\\nLoad text data\\nProcess text data\\nTabular\\nLoad tabular data\\nDataset repository\\nShare\\nCreate a dataset card\\nStructure your repository\\nConceptual guides\\nDatasets ü§ù Arrow\\nThe cache\\nDataset or IterableDataset\\nDataset features\\nBuild and loa\\n\\n### Link: documentation\\nText Generation Inference\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\ntext-generation-inference documentation\\nText Generation Inference\\ntext-generation-inference\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nEN\\nGetting started\\nText Generation Inference\\nQuick Tour\\nSupported Models\\nUsing TGI with Nvidia GPUs\\nUsing TGI with AMD GPUs\\nUsing TGI with Intel Gaudi\\nUsing TGI with AWS Trainium and Inferentia\\nUsing TGI with Google TPUs\\nUsing TGI with Intel GPUs\\nInstallation from source\\nMulti-backend support\\nInternal Architecture\\nUsage Statistics\\nTutorials\\nConsuming TGI\\nPreparing Model for Serving\\nServing Private & Gated Models\\nUsing TGI CLI\\nNon-core Model Serving\\nSafety\\nUsing Guidance, JSON, tools\\nVisual Language Models\\nMonitoring TGI with Prometheus and Grafana\\nTrain Medusa\\nBackends\\nNeuron\\nGaudi\\nTensorRT-LLM\\nLlamacpp\\nReference\\nAll TGI CLI options\\nExported Metrics\\nAPI Reference\\nConceptual Guides\\nV3 update, caching and chunking\\nStreaming\\nQuantization\\nTensor Parallelism\\nPagedAttention\\nSafetensors\\nFlash Attention\\nSpeculation (Medusa, ngram)\\nHow Guidance Works (via outlines)\\nLoRA (Low-Rank Adaptation)\\nExternal Resources\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\nCollaborate on models, datasets and Spaces\\nFaster examples with accelerated inference\\nSwitch between documentation themes\\nSign Up\\nto get started\\nText Generation Inference\\nText Generation Inference (TGI) is a toolkit for deploying and serving Large Language Models (LLMs). TGI en\\n\\n### Link: documentation\\nAccelerate\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nAccelerate documentation\\nAccelerate\\nAccelerate\\nüè° View all docs\\nAWS Trainium & Inferentia\\nAccelerate\\nArgilla\\nAutoTrain\\nBitsandbytes\\nChat UI\\nDataset viewer\\nDatasets\\nDeploying on AWS\\nDiffusers\\nDistilabel\\nEvaluate\\nGradio\\nHub\\nHub Python Library\\nHuggingface.js\\nInference Endpoints (dedicated)\\nInference Providers\\nKernels\\nLeRobot\\nLeaderboards\\nLighteval\\nMicrosoft Azure\\nOptimum\\nPEFT\\nSafetensors\\nSentence Transformers\\nTRL\\nTasks\\nText Embeddings Inference\\nText Generation Inference\\nTokenizers\\nTrackio\\nTransformers\\nTransformers.js\\nsmolagents\\ntimm\\nSearch documentation\\nmain\\nv1.11.0\\nv1.10.1\\nv1.9.0\\nv1.8.1\\nv1.7.0\\nv1.6.0\\nv1.5.2\\nv1.4.0\\nv1.3.0\\nv1.2.1\\nv1.1.0\\nv1.0.1\\nv0.34.2\\nv0.33.0\\nv0.32.0\\nv0.31.0\\nv0.30.1\\nv0.29.3\\nv0.28.0\\nv0.27.2\\nv0.26.1\\nv0.25.0\\nv0.24.0\\nv0.23.0\\nv0.22.0\\nv0.21.0\\nv0.20.3\\nv0.19.0\\nv0.18.0\\nv0.17.1\\nv0.16.0\\nv0.15.0\\nv0.14.0\\nv0.13.2\\nv0.12.0\\nv0.11.0\\nv0.10.0\\nv0.9.0\\nv0.8.0\\nv0.7.1\\nv0.6.0\\nv0.5.1\\nv0.4.0\\nv0.3.0\\nv0.2.1\\nv0.1.0\\nEN\\nGetting started\\nü§ó Accelerate\\nInstallation\\nQuicktour\\nTutorials\\nOverview\\nAdd Accelerate to your code\\nExecution process\\nTPU training\\nLaunching Accelerate scripts\\nLaunching distributed training from Jupyter Notebooks\\nHow to guides\\nAccelerate\\nStart Here!\\nModel memory estimator\\nModel quantization\\nExperiment trackers\\nProfiler\\nCheckpointing\\nTroubleshoot\\nExample Zoo\\nTraining\\nGradient accumulation\\nLocal SGD\\nLow precision (FP8) training\\nDeepSpeed\\nUsing multiple models with DeepSpeed\\nDDP Communication Hooks\\nFully Sharded Data Parallel\\nMegatron-LM\\nAmazon SageMaker\\nApple M1 GPUs\\nIntel CPU\\nIntel Gaudi\\nCompilation\\nInference\\nBig Model Inference\\nDistributed inference\\nConcepts and fundamentals\\nAccelerate\\'s internal mechanism\\nLoading big models into memory\\nComparing performance across distributed setups\\nExecuting and deferring jobs\\nGradient synchronization\\nFSDP vs DeepSpeed\\nFSDP1 vs FSDP2\\nContext parallelism\\nLow precision training methods\\nTraining on TPUs\\nReference\\nAccelerator\\nStateful classes\\nT'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_page_and_all_relevant_links(url=\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69969d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# brochure_system_prompt = \"\"\"\n",
    "# You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "# and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\n",
    "# Respond in markdown without code blocks.\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e19f59f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "336729ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages;\\nuse this information to build a short brochure of the company in markdown without code blocks.\\n\\n\\n## Landing Page:\\n\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\ndeepseek-ai/DeepSeek-OCR\\nUpdated\\nabout 17 hours ago\\n‚Ä¢\\n623k\\n‚Ä¢\\n1.82k\\nPaddlePaddle/PaddleOCR-VL\\nUpdated\\n1 day ago\\n‚Ä¢\\n14.8k\\n‚Ä¢\\n1.07k\\ntencent/HunyuanWorld-Mirror\\nUpdated\\nabout 12 hours ago\\n‚Ä¢\\n5.94k\\n‚Ä¢\\n330\\nkrea/krea-realtime-video\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n179\\nQwen/Qwen3-VL-8B-Instruct\\nUpdated\\n10 days ago\\n‚Ä¢\\n262k\\n‚Ä¢\\n320\\nBrowse 1M+ models\\nSpaces\\nRunning\\n514\\n514\\nveo3.1-fast\\nüê®\\nGenerate videos from text or images\\nRunning\\n15.4k\\n15.4k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nRunning\\non\\nZero\\n225\\n225\\nDeepSeek OCR Demo\\nüÜò\\nAn interactive demo for the DeepSeek-OCR model.\\nRunning\\n2.06k\\n2.06k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\nRunning\\n446\\n446\\nSora 2\\nüìâ\\nGenerate videos from text or images\\nBrowse 400k+ applications\\nDatasets\\nHuggingFaceFW/finewiki\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.66k\\n‚Ä¢\\n105\\nkarpathy/fineweb-edu-100b-shuffle\\nUpdated\\nabout 1 month ago\\n‚Ä¢\\n36k\\n‚Ä¢\\n101\\nnick007x/github-code-2025\\nUpdated\\n10 days ago\\n‚Ä¢\\n9.94k\\n‚Ä¢\\n72\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n36.7k\\n‚Ä¢\\n9.31k\\nHuggingFaceM4/FineVision\\nUpdated\\n4 days ago\\n‚Ä¢\\n229k\\n‚Ä¢\\n402\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at \\n## Relevant Links:\\n\\n\\n### Link: about page\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\ndeepseek-ai/DeepSeek-OCR\\nUpdated\\nabout 17 hours ago\\n‚Ä¢\\n623k\\n‚Ä¢\\n1.82k\\nPaddlePaddle/PaddleOCR-VL\\nUpdated\\n1 day ago\\n‚Ä¢\\n14.8k\\n‚Ä¢\\n1.07k\\ntencent/HunyuanWorld-Mirror\\nUpdated\\nabout 12 hours ago\\n‚Ä¢\\n5.94k\\n‚Ä¢\\n330\\nkrea/krea-realtime-video\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n179\\nQwen/Qwen3-VL-8B-Instruct\\nUpdated\\n10 days ago\\n‚Ä¢\\n262k\\n‚Ä¢\\n320\\nBrowse 1M+ models\\nSpaces\\nRunning\\n514\\n514\\nveo3.1-fast\\nüê®\\nGenerate videos from text or images\\nRunning\\n15.4k\\n15.4k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nRunning\\non\\nZero\\n225\\n225\\nDeepSeek OCR Demo\\nüÜò\\nAn interactive demo for the DeepSeek-OCR model.\\nRunning\\n2.06k\\n2.06k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\nRunning\\n446\\n446\\nSora 2\\nüìâ\\nGenerate videos from text or images\\nBrowse 400k+ applications\\nDatasets\\nHuggingFaceFW/finewiki\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.66k\\n‚Ä¢\\n105\\nkarpathy/fineweb-edu-100b-shuffle\\nUpdated\\nabout 1 month ago\\n‚Ä¢\\n36k\\n‚Ä¢\\n101\\nnick007x/github-code-2025\\nUpdated\\n10 days ago\\n‚Ä¢\\n9.94k\\n‚Ä¢\\n72\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n36.7k\\n‚Ä¢\\n9.31k\\nHuggingFaceM4/FineVision\\nUpdated\\n4 days ago\\n‚Ä¢\\n229k\\n‚Ä¢\\n402\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at \\n\\n### Link: models\\nModels ‚Äì Hugging Face\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEdit Models filters\\nMain\\nTasks\\nLibraries\\nLanguages\\nLicenses\\nOther\\nTasks\\nText Generation\\nAny-to-Any\\nImage-Text-to-Text\\nImage-to-Text\\nImage-to-Image\\nText-to-Image\\nText-to-Video\\nText-to-Speech\\n+ 42\\nParameters\\nReset Parameters\\n< 1B\\n6B\\n12B\\n32B\\n128B\\n> 500B\\n< 1B\\n> 500B\\nLibraries\\nPyTorch\\ngoogle-tensorflow\\nTensorFlow\\nJAX\\nTransformers\\nDiffusers\\nSafetensors\\nONNX\\nGGUF\\nTransformers.js\\nMLX\\nKeras\\n+ 41\\nApps\\nvLLM\\nTGI\\nllama.cpp\\nMLX LM\\nLM Studio\\nOllama\\nJan\\n+ 13\\nInference Providers\\nGroq\\nNovita\\nNebius AI\\nCerebras\\nSambaNova\\nNscale\\nfal\\nHyperbolic\\n+ 9\\nApply filters\\nModels\\nFull-text search\\nInference Available\\nAdd f'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1eb702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name:str, url:str, model:OpenAI=llama, model_name=\"llama3.1\"):\n",
    "    response = model.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2166221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 relevant links\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Hugging Face: The AI Collaboration Platform**\n",
       "\n",
       "At Hugging Face, we're building the future of artificial intelligence by enabling the community to collaborate on models, datasets, and applications. Our platform is designed to accelerate machine learning development and deployment.\n",
       "\n",
       "**Our Mission**\n",
       "----------------\n",
       "\n",
       "We aim to create a transparent and inclusive environment where researchers, developers, and businesses can work together to advance AI. By providing open-source tools and resources, we empower our community to build innovative solutions that benefit humanity.\n",
       "\n",
       "**Key Features**\n",
       "\n",
       "* **Open-Source Stack**: Our collection of open-source models, datasets, and libraries enables faster development and collaboration.\n",
       "* **Unlimited Public Models & Datasets**: Anyone can create, share, and collaborate on unlimited public models and datasets.\n",
       "* **Private Compute & Enterprise Solutions**: Paid options for enterprise-grade security, access controls, and dedicated support.\n",
       "\n",
       "**Community**\n",
       "-------------\n",
       "\n",
       "Hugging Face is home to the machine learning community. We host over 1 million models and hundreds of thousands of datasets. Our platform allows you to create a portfolio, share your work with the world, and build your AI profile.\n",
       "\n",
       "**Who We Serve**\n",
       "----------------\n",
       "\n",
       "* **Researchers**: Accelerate your ML research with our open-source stack.\n",
       "* **Developers**: Collaborate on models and applications using our platform.\n",
       "* **Businesses**: Leverage private compute and enterprise solutions for security and support.\n",
       "\n",
       "**Join Our Community**\n",
       "----------------------\n",
       "\n",
       "Sign up today to explore AI apps, browse millions of models and datasets, and collaborate with the Hugging Face community. Accelerate your machine learning journey with us!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(company_name=\"HuggingFace\", url=\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0910879",
   "metadata": {},
   "source": [
    "# Let's do typewrite animation i.e. stream the data which is created by LLM and show it on realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e820ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model:OpenAI=llama, model_name=\"llama3.1\"):\n",
    "    stream=model.chat.completions.create(model=model_name, messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ], stream=True)\n",
    "\n",
    "    response=\"\"\n",
    "    display_handle=display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    for chunk in stream:\n",
    "        response+=chunk.choices[0].delta.content or \"\"\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03589e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Welcome to Hugging Face**\n",
       "===============\n",
       "\n",
       "Hugging Face is a collaboration platform and open-source software that enables machine learning researchers, developers, and businesses to create, share, and use pre-trained models and datasets.\n",
       "\n",
       "**Community-driven Platform**\n",
       "-----------------------------\n",
       "\n",
       "*   **Collaboration**: Host and collaborate on unlimited public models, datasets, and applications.\n",
       "*   **Open-Source Stack**: Move faster with the HF Open source stack.\n",
       "*   **Portfolio Building**: Build your portfolio by sharing your work with the world and creating an ML profile.\n",
       "\n",
       "**Unlock Business Potential**\n",
       "-----------------------------\n",
       "\n",
       "*   **Accelerate Your AI Journey**: We provide paid Compute and Enterprise solutions for advanced business operations.\n",
       "*   **Enterprise-Grade Security and Support**: Give your team access to the most secure, scalable platform with dedicated support.\n",
       "\n",
       "**Explore Our Solutions**\n",
       "-------------------------\n",
       "\n",
       "### Models\n",
       "\n",
       "Discover our extensive collection of pre-trained models in various libraries, including but not limited to TensorFlow, PyTorch, ONNX, and Transformers. Browse over 1 million+ models.\n",
       "\n",
       "### Datasets\n",
       "\n",
       "Access a huge collection of datasets from various sources, facilitating tasks such as text generation, image-to-text, and text-to-image tasks. Browse our dataset repository.\n",
       "\n",
       "**Get Started Today**\n",
       "---------------------\n",
       "\n",
       "Signing up is easy! Click on the \"Sign Up\" button to begin exploring and collaborating with our platform."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb826871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
