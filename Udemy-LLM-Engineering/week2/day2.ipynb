{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b6a07d",
   "metadata": {},
   "source": [
    "# Gradio Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66605461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "from openai import OpenAI \n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f3f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dotenv file \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0a0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the keys \n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "gemini_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "ollama_api_key=os.getenv(\"OLLAMA_API_KEY\")\n",
    "\n",
    "# get the base url for gemini and ollama \n",
    "ollama_base_url=os.getenv(\"OLLAMA_BASE_URL\")\n",
    "gemini_base_url=os.getenv(\"GEMINI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f1c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instances \n",
    "openai=OpenAI()\n",
    "gemini=OpenAI(base_url=gemini_base_url, api_key=gemini_api_key)\n",
    "ollama=OpenAI(base_url=ollama_base_url, api_key=ollama_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663bc9eb",
   "metadata": {},
   "source": [
    "# Current Date for LLMs \n",
    "are never current system date. The model is trained with information till cut off date. LLMs have this date as current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe12d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create system message for ollama models \n",
    "system_message = \"You are a helpful assistant. And respond to question asked\"\n",
    "\n",
    "def message_ollama(prompt, model=\"mistral\"):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = ollama.chat.completions.create(model=model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4a170c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Today's date, as of my last update, is February 26, 2023. However, I recommend verifying this information because my data might not be current.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_ollama(\"What is today's date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4eede48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'However, I\\'m a large language model, I don\\'t have real-time access to the current date and time. But I can suggest ways for you to find out the current date.\\n\\nYou can check your device\\'s calendar or clock app, or search online for \"current date\" to get the latest information. If you want, I can also provide you with a virtual representation of today\\'s date as of our conversation, but please note that it will not be 100% accurate since my training data is based on a specific time period and may not reflect the current moment. Would you like me to give you an approximate date?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_ollama(\"What is today's date?\", \"llama3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdb680",
   "metadata": {},
   "source": [
    "# Creating user interface with Gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10411f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text:str):\n",
    "    print(f\"Shout function called with {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce934f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout function called with hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shout('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e8ef7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout function called with hello\n"
     ]
    }
   ],
   "source": [
    "# provide function call back to gradio\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2861f",
   "metadata": {},
   "source": [
    "# Sharing Gradio tool with Others\n",
    "you can share the gradio app in 2 ways \n",
    "1. Using deploy() method -> Suggested for longetivity \n",
    "2. Using parameter in launch(share=True) -> this will create a temporary instance on hugging face with 7 days retention period. For it to work you should have your notebook opened all the time \n",
    "* Important - Some antivirus software or companies LAN may not allow this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb0ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371992ce",
   "metadata": {},
   "source": [
    "### Adding inbrowser settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ffdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use parameter inbrowser=True within launch() function to launch the app in browser window \n",
    "# gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8c9f6",
   "metadata": {},
   "source": [
    "### Adding user authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2253f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True, auth=(\"rohit\", \"abcd@1234\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d68a60",
   "metadata": {},
   "source": [
    "### Forking dark mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ea2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout function called with hello\n"
     ]
    }
   ],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a274d36",
   "metadata": {},
   "source": [
    "### Add example text for users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aa4d243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout function called with hello\n",
      "Shout function called with howdy\n"
     ]
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message to be shouted\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    title=\"Shout\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b79dd6",
   "metadata": {},
   "source": [
    "# Add gradio to ollama call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5bd66e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for Mistral\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_ollama,\n",
    "    title=\"OLLAMA\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\", \"Explain 'Attention is all you need' paper in concise manner\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a021af",
   "metadata": {},
   "source": [
    "### Add streaming feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea1d4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ollama(prompt, model=\"mistral\"):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message}, \n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    stream=ollama.chat.completions.create(model=model, messages=messages, stream=True)\n",
    "    result=\"\" \n",
    "    for chunk in stream:\n",
    "        result+=chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14172eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for Mistral\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_ollama,\n",
    "    title=\"OLLAMA\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\", \"Explain 'Attention is all you need' paper in concise manner\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e09ee",
   "metadata": {},
   "source": [
    "# Add option for user to select the model for interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5902ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for the LLM\", lines=7)\n",
    "model_selector = gr.Dropdown([\"mistral\", \"llama3.1\", \"phi4-mini\", \"gemma3\"], label=\"Select model\", value=\"mistral\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_ollama,\n",
    "    title=\"LLMs\", \n",
    "    inputs=[message_input, model_selector],                         # pass model name in the parameter\n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "            [\"Explain the Transformer architecture to a layperson\", \"mistral\"],\n",
    "            [\"Explain the Transformer architecture to an aspiring AI engineer\", \"llama3.1\"]\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5be6df",
   "metadata": {},
   "source": [
    "# Creating Company brochure - Next level of Week1 Excercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "138c0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import fetch_website_contents, fetch_website_links\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc4139e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bcd199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f76e80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url:str, model:OpenAI=ollama, model_name:str=\"gemma3\"):\n",
    "    response=model.chat.completions.create(model=model_name, messages=[\n",
    "        {\"role\" : \"system\", \"content\" : link_system_prompt}, \n",
    "        {\"role\" : \"user\", \"content\" : get_links_user_prompt(url)}], response_format={\"type\" : \"json_object\"\n",
    "    })\n",
    "\n",
    "    result=response.choices[0].message.content\n",
    "    links=json.loads(result)\n",
    "\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43d434db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    contents = fetch_website_contents(url)\n",
    "    relevant_links = select_relevant_links(url)\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n### Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link[\"url\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a1c4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "557711e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "253fb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model_name=\"llama3.1\", model:OpenAI=ollama):\n",
    "    stream=model.chat.completions.create(model=model_name, messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ], stream=True)\n",
    "\n",
    "    response=\"\"\n",
    "    # display_handle=display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    for chunk in stream:\n",
    "        response+=chunk.choices[0].delta.content or \"\"\n",
    "        # update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "        yield response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18a642a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 relevant links\n"
     ]
    }
   ],
   "source": [
    "name_input = gr.Textbox(label=\"Company name:\")\n",
    "url_input = gr.Textbox(label=\"Landing page URL including http:// or https://\")\n",
    "model_selector = gr.Dropdown([\"mistral\", \"llama3.1\", \"phi4-mini\", \"gemma3\"], label=\"Select model\", value=\"mistral\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view=gr.Interface(\n",
    "    fn=stream_brochure, \n",
    "    title=\"Generate Brochure for companies\",\n",
    "    inputs=[name_input, url_input, model_selector],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "            [\"Hugging Face\", \"https://huggingface.co\", \"mistral\"],\n",
    "            [\"Edward Donner\", \"https://edwarddonner.com\", \"llama3.1\"]\n",
    "        ], \n",
    "    flagging_mode=\"never\"    \n",
    "\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69206e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
