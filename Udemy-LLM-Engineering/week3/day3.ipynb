{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9e69ab",
   "metadata": {},
   "source": [
    "# Tokenizers\n",
    "\n",
    "Please can I bring you back to the wonderful Google Colab where we'll look at different Tokenizers:\n",
    "\n",
    "https://colab.research.google.com/drive/1WD6Y2N7ctQi1X9wa6rpkg8UfyA4iSVuz?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4663f",
   "metadata": {},
   "source": [
    "# Exception - \n",
    "Instead of running this on collab. We will run this on Local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c8348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer\n",
    "import os \n",
    "from dotenv import load_dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345d9f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF key looks good so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Log in to Hugging Face\n",
    "load_dotenv(override=True)\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if hf_token and hf_token.startswith(\"hf_\"):\n",
    "  print(\"HF key looks good so far\")\n",
    "else:\n",
    "  print(\"HF key is not set - please click the key in the left sidebar\")\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b29c14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n",
      "NOT CONNECTED TO A T4\n"
     ]
    }
   ],
   "source": [
    "# Check Google Colab GPU - This is not needed on Macbook\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "  if gpu_info.find('Tesla T4') >= 0:\n",
    "    print(\"Success - Connected to a T4\")\n",
    "  else:\n",
    "    print(\"NOT CONNECTED TO A T4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b83fe6",
   "metadata": {},
   "source": [
    "Llama access was granted on Hugging face in less than few minutes \n",
    "\n",
    "# Accessing Llama 3.1 from Meta\n",
    "\n",
    "In order to use the fantastic Llama 3.1, Meta does require you to sign their terms of service.\n",
    "\n",
    "Visit their model instructions page in Hugging Face:\n",
    "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B\n",
    "\n",
    "At the top of the page are instructions on how to agree to their terms. If possible, you should use the same email as your huggingface account.\n",
    "\n",
    "In my experience approval comes in a couple of minutes. Once you've been approved for any 3.1 model, it applies to the whole 3.1 family of models. For whatever reason, occasionally Meta doesn't approve access. If that happens to you, please follow [this](https://colab.research.google.com/drive/1deJO03YZTXUwcq2vzxWbiBhrRuI29Vo8?usp=sharing) troubleshooting.\n",
    "\n",
    "If the next cell gives you an error, then please check:  \n",
    "1. Are you logged in to HuggingFace? Try running `login()` to check your key works\n",
    "2. Did you set up your API key with full read and write permissions?\n",
    "3. If you visit the Llama3.1 page with the link above, does it show that you have access to the model near the top?\n",
    "\n",
    "I've also set up this troubleshooting colab to try to diagnose any HuggingFace connectivity issues:  \n",
    "https://colab.research.google.com/drive/1deJO03YZTXUwcq2vzxWbiBhrRuI29Vo8?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c5a39",
   "metadata": {},
   "source": [
    "# Get Token Details for Llama base model\n",
    "\n",
    "Base Model in Hugging Face: \"base model\" is a pre-trained model that serves as a foundation for other, more specialized models, often a general model that has been fine-tuned for a specific task. It is a fundamental building block that can be customized through fine-tuning to perform new tasks like sentiment analysis, translation, or summarization. Examples include a base language model like bert-base-uncased or a base vision-language model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7681c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token details for llama pretrained \"base model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3.1-8B', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7299324d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000,\n",
       " 40,\n",
       " 1097,\n",
       " 12304,\n",
       " 311,\n",
       " 1501,\n",
       " 9857,\n",
       " 12509,\n",
       " 304,\n",
       " 1957,\n",
       " 311,\n",
       " 856,\n",
       " 445,\n",
       " 11237,\n",
       " 25175]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the tokens generated for text below \n",
    "text = \"I am excited to show Tokenizers in action to my LLM engineers\"\n",
    "tokens = tokenizer.encode(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1eaa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61 characters, 12 words and 15 tokens\n"
     ]
    }
   ],
   "source": [
    "# get lengths \n",
    "character_count = len(text)\n",
    "word_count = len(text.split(' '))\n",
    "token_count = len(tokens)\n",
    "print(f\"There are {character_count} characters, {word_count} words and {token_count} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1fbee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>I am excited to show Tokenizers in action to my LLM engineers'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets decode the tokens generated. Pay careful attention how llama inserts special tokens \n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093d04df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>',\n",
       " 'I',\n",
       " ' am',\n",
       " ' excited',\n",
       " ' to',\n",
       " ' show',\n",
       " ' Token',\n",
       " 'izers',\n",
       " ' in',\n",
       " ' action',\n",
       " ' to',\n",
       " ' my',\n",
       " ' L',\n",
       " 'LM',\n",
       " ' engineers']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is another way to see which token means which word in the sentence \n",
    "tokenizer.batch_decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83f7924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|begin_of_text|>': 128000,\n",
       " '<|end_of_text|>': 128001,\n",
       " '<|reserved_special_token_0|>': 128002,\n",
       " '<|reserved_special_token_1|>': 128003,\n",
       " '<|finetune_right_pad_id|>': 128004,\n",
       " '<|reserved_special_token_2|>': 128005,\n",
       " '<|start_header_id|>': 128006,\n",
       " '<|end_header_id|>': 128007,\n",
       " '<|eom_id|>': 128008,\n",
       " '<|eot_id|>': 128009,\n",
       " '<|python_tag|>': 128010,\n",
       " '<|reserved_special_token_3|>': 128011,\n",
       " '<|reserved_special_token_4|>': 128012,\n",
       " '<|reserved_special_token_5|>': 128013,\n",
       " '<|reserved_special_token_6|>': 128014,\n",
       " '<|reserved_special_token_7|>': 128015,\n",
       " '<|reserved_special_token_8|>': 128016,\n",
       " '<|reserved_special_token_9|>': 128017,\n",
       " '<|reserved_special_token_10|>': 128018,\n",
       " '<|reserved_special_token_11|>': 128019,\n",
       " '<|reserved_special_token_12|>': 128020,\n",
       " '<|reserved_special_token_13|>': 128021,\n",
       " '<|reserved_special_token_14|>': 128022,\n",
       " '<|reserved_special_token_15|>': 128023,\n",
       " '<|reserved_special_token_16|>': 128024,\n",
       " '<|reserved_special_token_17|>': 128025,\n",
       " '<|reserved_special_token_18|>': 128026,\n",
       " '<|reserved_special_token_19|>': 128027,\n",
       " '<|reserved_special_token_20|>': 128028,\n",
       " '<|reserved_special_token_21|>': 128029,\n",
       " '<|reserved_special_token_22|>': 128030,\n",
       " '<|reserved_special_token_23|>': 128031,\n",
       " '<|reserved_special_token_24|>': 128032,\n",
       " '<|reserved_special_token_25|>': 128033,\n",
       " '<|reserved_special_token_26|>': 128034,\n",
       " '<|reserved_special_token_27|>': 128035,\n",
       " '<|reserved_special_token_28|>': 128036,\n",
       " '<|reserved_special_token_29|>': 128037,\n",
       " '<|reserved_special_token_30|>': 128038,\n",
       " '<|reserved_special_token_31|>': 128039,\n",
       " '<|reserved_special_token_32|>': 128040,\n",
       " '<|reserved_special_token_33|>': 128041,\n",
       " '<|reserved_special_token_34|>': 128042,\n",
       " '<|reserved_special_token_35|>': 128043,\n",
       " '<|reserved_special_token_36|>': 128044,\n",
       " '<|reserved_special_token_37|>': 128045,\n",
       " '<|reserved_special_token_38|>': 128046,\n",
       " '<|reserved_special_token_39|>': 128047,\n",
       " '<|reserved_special_token_40|>': 128048,\n",
       " '<|reserved_special_token_41|>': 128049,\n",
       " '<|reserved_special_token_42|>': 128050,\n",
       " '<|reserved_special_token_43|>': 128051,\n",
       " '<|reserved_special_token_44|>': 128052,\n",
       " '<|reserved_special_token_45|>': 128053,\n",
       " '<|reserved_special_token_46|>': 128054,\n",
       " '<|reserved_special_token_47|>': 128055,\n",
       " '<|reserved_special_token_48|>': 128056,\n",
       " '<|reserved_special_token_49|>': 128057,\n",
       " '<|reserved_special_token_50|>': 128058,\n",
       " '<|reserved_special_token_51|>': 128059,\n",
       " '<|reserved_special_token_52|>': 128060,\n",
       " '<|reserved_special_token_53|>': 128061,\n",
       " '<|reserved_special_token_54|>': 128062,\n",
       " '<|reserved_special_token_55|>': 128063,\n",
       " '<|reserved_special_token_56|>': 128064,\n",
       " '<|reserved_special_token_57|>': 128065,\n",
       " '<|reserved_special_token_58|>': 128066,\n",
       " '<|reserved_special_token_59|>': 128067,\n",
       " '<|reserved_special_token_60|>': 128068,\n",
       " '<|reserved_special_token_61|>': 128069,\n",
       " '<|reserved_special_token_62|>': 128070,\n",
       " '<|reserved_special_token_63|>': 128071,\n",
       " '<|reserved_special_token_64|>': 128072,\n",
       " '<|reserved_special_token_65|>': 128073,\n",
       " '<|reserved_special_token_66|>': 128074,\n",
       " '<|reserved_special_token_67|>': 128075,\n",
       " '<|reserved_special_token_68|>': 128076,\n",
       " '<|reserved_special_token_69|>': 128077,\n",
       " '<|reserved_special_token_70|>': 128078,\n",
       " '<|reserved_special_token_71|>': 128079,\n",
       " '<|reserved_special_token_72|>': 128080,\n",
       " '<|reserved_special_token_73|>': 128081,\n",
       " '<|reserved_special_token_74|>': 128082,\n",
       " '<|reserved_special_token_75|>': 128083,\n",
       " '<|reserved_special_token_76|>': 128084,\n",
       " '<|reserved_special_token_77|>': 128085,\n",
       " '<|reserved_special_token_78|>': 128086,\n",
       " '<|reserved_special_token_79|>': 128087,\n",
       " '<|reserved_special_token_80|>': 128088,\n",
       " '<|reserved_special_token_81|>': 128089,\n",
       " '<|reserved_special_token_82|>': 128090,\n",
       " '<|reserved_special_token_83|>': 128091,\n",
       " '<|reserved_special_token_84|>': 128092,\n",
       " '<|reserved_special_token_85|>': 128093,\n",
       " '<|reserved_special_token_86|>': 128094,\n",
       " '<|reserved_special_token_87|>': 128095,\n",
       " '<|reserved_special_token_88|>': 128096,\n",
       " '<|reserved_special_token_89|>': 128097,\n",
       " '<|reserved_special_token_90|>': 128098,\n",
       " '<|reserved_special_token_91|>': 128099,\n",
       " '<|reserved_special_token_92|>': 128100,\n",
       " '<|reserved_special_token_93|>': 128101,\n",
       " '<|reserved_special_token_94|>': 128102,\n",
       " '<|reserved_special_token_95|>': 128103,\n",
       " '<|reserved_special_token_96|>': 128104,\n",
       " '<|reserved_special_token_97|>': 128105,\n",
       " '<|reserved_special_token_98|>': 128106,\n",
       " '<|reserved_special_token_99|>': 128107,\n",
       " '<|reserved_special_token_100|>': 128108,\n",
       " '<|reserved_special_token_101|>': 128109,\n",
       " '<|reserved_special_token_102|>': 128110,\n",
       " '<|reserved_special_token_103|>': 128111,\n",
       " '<|reserved_special_token_104|>': 128112,\n",
       " '<|reserved_special_token_105|>': 128113,\n",
       " '<|reserved_special_token_106|>': 128114,\n",
       " '<|reserved_special_token_107|>': 128115,\n",
       " '<|reserved_special_token_108|>': 128116,\n",
       " '<|reserved_special_token_109|>': 128117,\n",
       " '<|reserved_special_token_110|>': 128118,\n",
       " '<|reserved_special_token_111|>': 128119,\n",
       " '<|reserved_special_token_112|>': 128120,\n",
       " '<|reserved_special_token_113|>': 128121,\n",
       " '<|reserved_special_token_114|>': 128122,\n",
       " '<|reserved_special_token_115|>': 128123,\n",
       " '<|reserved_special_token_116|>': 128124,\n",
       " '<|reserved_special_token_117|>': 128125,\n",
       " '<|reserved_special_token_118|>': 128126,\n",
       " '<|reserved_special_token_119|>': 128127,\n",
       " '<|reserved_special_token_120|>': 128128,\n",
       " '<|reserved_special_token_121|>': 128129,\n",
       " '<|reserved_special_token_122|>': 128130,\n",
       " '<|reserved_special_token_123|>': 128131,\n",
       " '<|reserved_special_token_124|>': 128132,\n",
       " '<|reserved_special_token_125|>': 128133,\n",
       " '<|reserved_special_token_126|>': 128134,\n",
       " '<|reserved_special_token_127|>': 128135,\n",
       " '<|reserved_special_token_128|>': 128136,\n",
       " '<|reserved_special_token_129|>': 128137,\n",
       " '<|reserved_special_token_130|>': 128138,\n",
       " '<|reserved_special_token_131|>': 128139,\n",
       " '<|reserved_special_token_132|>': 128140,\n",
       " '<|reserved_special_token_133|>': 128141,\n",
       " '<|reserved_special_token_134|>': 128142,\n",
       " '<|reserved_special_token_135|>': 128143,\n",
       " '<|reserved_special_token_136|>': 128144,\n",
       " '<|reserved_special_token_137|>': 128145,\n",
       " '<|reserved_special_token_138|>': 128146,\n",
       " '<|reserved_special_token_139|>': 128147,\n",
       " '<|reserved_special_token_140|>': 128148,\n",
       " '<|reserved_special_token_141|>': 128149,\n",
       " '<|reserved_special_token_142|>': 128150,\n",
       " '<|reserved_special_token_143|>': 128151,\n",
       " '<|reserved_special_token_144|>': 128152,\n",
       " '<|reserved_special_token_145|>': 128153,\n",
       " '<|reserved_special_token_146|>': 128154,\n",
       " '<|reserved_special_token_147|>': 128155,\n",
       " '<|reserved_special_token_148|>': 128156,\n",
       " '<|reserved_special_token_149|>': 128157,\n",
       " '<|reserved_special_token_150|>': 128158,\n",
       " '<|reserved_special_token_151|>': 128159,\n",
       " '<|reserved_special_token_152|>': 128160,\n",
       " '<|reserved_special_token_153|>': 128161,\n",
       " '<|reserved_special_token_154|>': 128162,\n",
       " '<|reserved_special_token_155|>': 128163,\n",
       " '<|reserved_special_token_156|>': 128164,\n",
       " '<|reserved_special_token_157|>': 128165,\n",
       " '<|reserved_special_token_158|>': 128166,\n",
       " '<|reserved_special_token_159|>': 128167,\n",
       " '<|reserved_special_token_160|>': 128168,\n",
       " '<|reserved_special_token_161|>': 128169,\n",
       " '<|reserved_special_token_162|>': 128170,\n",
       " '<|reserved_special_token_163|>': 128171,\n",
       " '<|reserved_special_token_164|>': 128172,\n",
       " '<|reserved_special_token_165|>': 128173,\n",
       " '<|reserved_special_token_166|>': 128174,\n",
       " '<|reserved_special_token_167|>': 128175,\n",
       " '<|reserved_special_token_168|>': 128176,\n",
       " '<|reserved_special_token_169|>': 128177,\n",
       " '<|reserved_special_token_170|>': 128178,\n",
       " '<|reserved_special_token_171|>': 128179,\n",
       " '<|reserved_special_token_172|>': 128180,\n",
       " '<|reserved_special_token_173|>': 128181,\n",
       " '<|reserved_special_token_174|>': 128182,\n",
       " '<|reserved_special_token_175|>': 128183,\n",
       " '<|reserved_special_token_176|>': 128184,\n",
       " '<|reserved_special_token_177|>': 128185,\n",
       " '<|reserved_special_token_178|>': 128186,\n",
       " '<|reserved_special_token_179|>': 128187,\n",
       " '<|reserved_special_token_180|>': 128188,\n",
       " '<|reserved_special_token_181|>': 128189,\n",
       " '<|reserved_special_token_182|>': 128190,\n",
       " '<|reserved_special_token_183|>': 128191,\n",
       " '<|reserved_special_token_184|>': 128192,\n",
       " '<|reserved_special_token_185|>': 128193,\n",
       " '<|reserved_special_token_186|>': 128194,\n",
       " '<|reserved_special_token_187|>': 128195,\n",
       " '<|reserved_special_token_188|>': 128196,\n",
       " '<|reserved_special_token_189|>': 128197,\n",
       " '<|reserved_special_token_190|>': 128198,\n",
       " '<|reserved_special_token_191|>': 128199,\n",
       " '<|reserved_special_token_192|>': 128200,\n",
       " '<|reserved_special_token_193|>': 128201,\n",
       " '<|reserved_special_token_194|>': 128202,\n",
       " '<|reserved_special_token_195|>': 128203,\n",
       " '<|reserved_special_token_196|>': 128204,\n",
       " '<|reserved_special_token_197|>': 128205,\n",
       " '<|reserved_special_token_198|>': 128206,\n",
       " '<|reserved_special_token_199|>': 128207,\n",
       " '<|reserved_special_token_200|>': 128208,\n",
       " '<|reserved_special_token_201|>': 128209,\n",
       " '<|reserved_special_token_202|>': 128210,\n",
       " '<|reserved_special_token_203|>': 128211,\n",
       " '<|reserved_special_token_204|>': 128212,\n",
       " '<|reserved_special_token_205|>': 128213,\n",
       " '<|reserved_special_token_206|>': 128214,\n",
       " '<|reserved_special_token_207|>': 128215,\n",
       " '<|reserved_special_token_208|>': 128216,\n",
       " '<|reserved_special_token_209|>': 128217,\n",
       " '<|reserved_special_token_210|>': 128218,\n",
       " '<|reserved_special_token_211|>': 128219,\n",
       " '<|reserved_special_token_212|>': 128220,\n",
       " '<|reserved_special_token_213|>': 128221,\n",
       " '<|reserved_special_token_214|>': 128222,\n",
       " '<|reserved_special_token_215|>': 128223,\n",
       " '<|reserved_special_token_216|>': 128224,\n",
       " '<|reserved_special_token_217|>': 128225,\n",
       " '<|reserved_special_token_218|>': 128226,\n",
       " '<|reserved_special_token_219|>': 128227,\n",
       " '<|reserved_special_token_220|>': 128228,\n",
       " '<|reserved_special_token_221|>': 128229,\n",
       " '<|reserved_special_token_222|>': 128230,\n",
       " '<|reserved_special_token_223|>': 128231,\n",
       " '<|reserved_special_token_224|>': 128232,\n",
       " '<|reserved_special_token_225|>': 128233,\n",
       " '<|reserved_special_token_226|>': 128234,\n",
       " '<|reserved_special_token_227|>': 128235,\n",
       " '<|reserved_special_token_228|>': 128236,\n",
       " '<|reserved_special_token_229|>': 128237,\n",
       " '<|reserved_special_token_230|>': 128238,\n",
       " '<|reserved_special_token_231|>': 128239,\n",
       " '<|reserved_special_token_232|>': 128240,\n",
       " '<|reserved_special_token_233|>': 128241,\n",
       " '<|reserved_special_token_234|>': 128242,\n",
       " '<|reserved_special_token_235|>': 128243,\n",
       " '<|reserved_special_token_236|>': 128244,\n",
       " '<|reserved_special_token_237|>': 128245,\n",
       " '<|reserved_special_token_238|>': 128246,\n",
       " '<|reserved_special_token_239|>': 128247,\n",
       " '<|reserved_special_token_240|>': 128248,\n",
       " '<|reserved_special_token_241|>': 128249,\n",
       " '<|reserved_special_token_242|>': 128250,\n",
       " '<|reserved_special_token_243|>': 128251,\n",
       " '<|reserved_special_token_244|>': 128252,\n",
       " '<|reserved_special_token_245|>': 128253,\n",
       " '<|reserved_special_token_246|>': 128254,\n",
       " '<|reserved_special_token_247|>': 128255}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary details of this tokenizer for special tokens\n",
    "tokenizer.get_added_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e963a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a38e1",
   "metadata": {},
   "source": [
    "### This means there are 128000 words with token values and 256 special tokens  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27f5ac",
   "metadata": {},
   "source": [
    "# Instruct variant of the model \n",
    "IMany models have a variant that has been trained for use in Chats.\n",
    "These are typically labelled with the word \"Instruct\" at the end.\n",
    "They have been trained to expect prompts with a particular format that includes system, user and assistant prompts.\n",
    "\n",
    "There is a utility method ```apply_chat_template``` that will convert from the messages list format we are familiar with, into the right input prompt for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb8c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3.1-8B-Instruct', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de885edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Tell a light-hearted joke for a room of Data Scientists<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# construct the message format you want \n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of Data Scientists\"}\n",
    "  ]\n",
    "\n",
    "# apply this as template for model to respond in this way\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848373b2",
   "metadata": {},
   "source": [
    "```\n",
    "LLM is just a Data Science model that takes a sequence of numbers and predicts the probability of the next number! You can't pass a bunch of Python objects into a statistical model!\n",
    "\n",
    "And now you have the missing piece of the puzzle..\n",
    "The messages in OpenAI format get converted:\n",
    "\n",
    "1. ...into a sequence of words with special tags to separate the System, User, Assistant prompt\n",
    "2. ...then the words are broken down into fragments - \"tokens\"\n",
    "3. ...then the tokens are replaced with Token IDs - and this is the input sequence\n",
    "The input to an LLM is a sequence of Token IDs. The output is the probability distribution of the next Token ID to follow this input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8e2f0",
   "metadata": {},
   "source": [
    "# More Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71e0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHI4 = \"microsoft/Phi-4-mini-instruct\"\n",
    "DEEPSEEK = \"deepseek-ai/DeepSeek-V3.1\"\n",
    "QWEN_CODER = \"Qwen/Qwen2.5-Coder-7B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5d1d7",
   "metadata": {},
   "source": [
    "# ATTENTION - refer material on cloud LLM Engineering - Week 3 Day 3.ipynb. Below is taking way too long to get the tokenizer.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a6994e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model was giving me errors - so making them single process to avoid deadlocks \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3f238a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2cc75928bf4737b44728a3938dc5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/15.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# create ph4 tokenizer \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m phi4_tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPHI4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# give a text \u001b[39;00m\n\u001b[32m      5\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mI am curiously excited to show Hugging Face Tokenizers in action to my LLM engineers\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1140\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1138\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist or is not currently imported.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1139\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2060\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2058\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2059\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2060\u001b[39m         resolved_vocab_files[file_id] = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2075\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   2076\u001b[39m         \u001b[38;5;66;03m# Re-raise any error raised by cached_file in order to get a helpful error message\u001b[39;00m\n\u001b[32m   2077\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         snapshot_download(\n\u001b[32m    495\u001b[39m             path_or_repo_id,\n\u001b[32m    496\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    506\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    988\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    989\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1005\u001b[39m     )\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1168\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1181\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1720\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[32m   1719\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1720\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:621\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    610\u001b[39m     displayed_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(â€¦)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    612\u001b[39m progress_cm = _get_progress_bar_context(\n\u001b[32m    613\u001b[39m     desc=displayed_filename,\n\u001b[32m    614\u001b[39m     log_level=logger.getEffectiveLevel(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    618\u001b[39m     _tqdm_bar=_tqdm_bar,\n\u001b[32m    619\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_cm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mprogress_updater\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/tqdm/std.py:1140\u001b[39m, in \u001b[36mtqdm.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1142\u001b[39m         \u001b[38;5;66;03m# maybe eager thread cleanup upon external error\u001b[39;00m\n\u001b[32m   1143\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (exc_type, exc_value, traceback) == (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/tqdm/notebook.py:275\u001b[39m, in \u001b[36mtqdm_notebook.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Try to detect if there was an error or KeyboardInterrupt\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# in manual mode: if n < total, things probably got wrong\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n < \u001b[38;5;28mself\u001b[39m.total:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/tqdm/std.py:1275\u001b[39m, in \u001b[36mtqdm.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;66;03m# decrement instance pos and remove from internal set\u001b[39;00m\n\u001b[32m   1274\u001b[39m pos = \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m.pos)\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decr_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_print_t < \u001b[38;5;28mself\u001b[39m.start_t + \u001b[38;5;28mself\u001b[39m.delay:\n\u001b[32m   1278\u001b[39m     \u001b[38;5;66;03m# haven't ever displayed; nothing to clear\u001b[39;00m\n\u001b[32m   1279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/tqdm/std.py:696\u001b[39m, in \u001b[36mtqdm._decr_instances\u001b[39m\u001b[34m(cls, instance)\u001b[39m\n\u001b[32m    686\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decr_instances\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[32m    688\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    689\u001b[39m \u001b[33;03m    Remove from list and reposition another unfixed bar\u001b[39;00m\n\u001b[32m    690\u001b[39m \u001b[33;03m    to fill the new gap.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m \u001b[33;03m    (tqdm<=4.44.1 moved ALL subsequent unfixed bars up.)\u001b[39;00m\n\u001b[32m    695\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lock\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_instances\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/tqdm/std.py:111\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-abhirohit@gmail.com/My Drive/9. Programming_Workspace/Github-Programs/Python_Workspace/Udemy-LLM-Engineering/.venv/lib/python3.12/site-packages/tqdm/std.py:104\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.acquire\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, *a, **k):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.locks:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# create ph4 tokenizer \n",
    "phi4_tokenizer = AutoTokenizer.from_pretrained(PHI4)\n",
    "\n",
    "# give a text \n",
    "text = \"I am curiously excited to show Hugging Face Tokenizers in action to my LLM engineers\"\n",
    "\n",
    "# Print llama details \n",
    "print(\"Llama:\")\n",
    "tokens = tokenizer.encode(text)\n",
    "print(tokens)\n",
    "print(tokenizer.batch_decode(tokens))\n",
    "\n",
    "# Print PHI4 details for same text\n",
    "print(\"\\nPhi 4:\")\n",
    "tokens = phi4_tokenizer.encode(text)\n",
    "print(tokens)\n",
    "print(phi4_tokenizer.batch_decode(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90852607",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_tokenizer = AutoTokenizer.from_pretrained(DEEPSEEK)\n",
    "\n",
    "text = \"I am curiously excited to show Hugging Face Tokenizers in action to my LLM engineers\"\n",
    "print(tokenizer.encode(text))\n",
    "print()\n",
    "print(phi4_tokenizer.encode(text))\n",
    "print()\n",
    "print(deepseek_tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf8f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
